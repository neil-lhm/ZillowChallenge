{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "trainFile = \"train_2016_v2.csv\"\n",
    "df_train = pd.read_csv(trainFile, header = 0, skipinitialspace=True, engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "propertiesFile = \"properties_2016.csv\"\n",
    "# use float dtype to handle na in pandas\n",
    "columnDtypes = {'parcelid':int, 'airconditioningtypeid':str, 'architecturalstyletypeid':str, 'basementsqft':float,\n",
    "                'bathroomcnt':float, 'bedroomcnt':float, 'buildingclasstypeid':str, 'buildingqualitytypeid':str,\n",
    "                'calculatedbathnbr':float, 'decktypeid':str, 'finishedfloor1squarefeet':float, 'calculatedfinishedsquarefeet':float,\n",
    "                'finishedsquarefeet12':float, 'finishedsquarefeet13':float, 'finishedsquarefeet15':float, 'finishedsquarefeet50':float,\n",
    "                'finishedsquarefeet6':float, 'fips':str, 'fireplacecnt':float, 'fullbathcnt':float, 'garagecarcnt':float, 'garagetotalsqft':float,\n",
    "                'hashottuborspa':str, 'heatingorsystemtypeid':str, 'latitude':float, 'longitude':float, 'lotsizesquarefeet':float, 'poolcnt':float,\n",
    "                'poolsizesum':float, 'pooltypeid10':str, 'pooltypeid2':str, 'pooltypeid7':str, 'propertycountylandusecode':str,\n",
    "                'propertylandusetypeid':str, 'propertyzoningdesc':str, 'rawcensustractandblock':float, 'regionidcity':str,\n",
    "                'regionidcounty':str, 'regionidneighborhood':str, 'regionidzip':str, 'roomcnt':float, 'storytypeid':float,\n",
    "                'threequarterbathnbr': float, 'typeconstructiontypeid':float, 'unitcnt':float, 'yardbuildingsqft17':float,\n",
    "                'yardbuildingsqft26':float, 'yearbuilt':float, 'numberofstories': float, 'fireplaceflag':str, 'structuretaxvaluedollarcnt':float,\n",
    "                'taxvaluedollarcnt': float, 'assessmentyear':float, 'landtaxvaluedollarcnt': float, 'taxamount':float, 'taxdelinquencyflag':str,\n",
    "                'taxdelinquencyyear': float, 'censustractandblock':float}\n",
    "df_properties = pd.read_csv(propertiesFile, header = 0, skipinitialspace=True, dtype=columnDtypes, \n",
    "                            engine=\"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = pd.merge(df_properties, df_train, how=\"inner\", on=[\"parcelid\"]);\n",
    "inter.shape;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter.isnull().sum(axis=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90275, 26)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter.dropna(axis=1, thresh = int(inter.shape[0] * .9), inplace=True);\n",
    "inter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na in float columns with 0, and string columns with empty string\n",
    "float_columns_with_na = [\n",
    "    'calculatedbathnbr', 'calculatedfinishedsquarefeet', 'finishedsquarefeet12', 'fullbathcnt', \n",
    "    'yearbuilt', 'structuretaxvaluedollarcnt', 'taxvaluedollarcnt', 'landtaxvaluedollarcnt', \n",
    "    'taxamount', 'censustractandblock'\n",
    "]\n",
    "\n",
    "string_columns_with_na = [\n",
    "    'propertycountylandusecode', 'regionidcity', 'regionidzip'\n",
    "]\n",
    "inter[float_columns_with_na] = inter[float_columns_with_na].fillna(0)\n",
    "inter[string_columns_with_na] = inter[string_columns_with_na].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parcelid                        0\n",
       "bathroomcnt                     0\n",
       "bedroomcnt                      0\n",
       "calculatedbathnbr               0\n",
       "calculatedfinishedsquarefeet    0\n",
       "finishedsquarefeet12            0\n",
       "fips                            0\n",
       "fullbathcnt                     0\n",
       "latitude                        0\n",
       "longitude                       0\n",
       "propertycountylandusecode       0\n",
       "propertylandusetypeid           0\n",
       "rawcensustractandblock          0\n",
       "regionidcity                    0\n",
       "regionidcounty                  0\n",
       "regionidzip                     0\n",
       "roomcnt                         0\n",
       "yearbuilt                       0\n",
       "structuretaxvaluedollarcnt      0\n",
       "taxvaluedollarcnt               0\n",
       "assessmentyear                  0\n",
       "landtaxvaluedollarcnt           0\n",
       "taxamount                       0\n",
       "censustractandblock             0\n",
       "logerror                        0\n",
       "transactiondate                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "datasetSize = inter.shape[0]\n",
    "trainRatio = .8\n",
    "trainIndex = set(np.random.choice(datasetSize, int(datasetSize * trainRatio), replace=False))\n",
    "testIndex = set(range(datasetSize)) - trainIndex\n",
    "# cast to list to indexing dataframe\n",
    "trainIndex = list(trainIndex)\n",
    "testIndex = list(testIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_trainx = inter.iloc[trainIndex]\n",
    "trainy = df_trainx['logerror'].astype(float)\n",
    "df_trainx = df_trainx.drop(['logerror', 'transactiondate'], axis=1)\n",
    "df_testx = inter.iloc[testIndex]\n",
    "testy = df_testx['logerror'].astype(float)\n",
    "df_testx = df_testx.drop(['logerror', 'transactiondate'], axis=1)\n",
    "\n",
    "df_trainx.set_index('parcelid');\n",
    "df_testx.set_index('parcelid');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn(df_trainx, trainy, num_epochs, shuffle=True, batch_size=100, num_threads=1):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x=df_trainx,\n",
    "        y=trainy,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=num_epochs,\n",
    "        shuffle=shuffle,\n",
    "        num_threads=num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model_columns():\n",
    "\n",
    "    # continous features no bukcet. To-do: use buckets to handle -1s used to fill nas\n",
    "    bathroomcnt = tf.feature_column.numeric_column(\"bathroomcnt\")\n",
    "    bedroomcnt = tf.feature_column.numeric_column(\"bedroomcnt\")\n",
    "    calculatedbathnbr = tf.feature_column.numeric_column('calculatedbathnbr')\n",
    "    calculatedfinishedsquarefeet = tf.feature_column.numeric_column('calculatedfinishedsquarefeet')\n",
    "    finishedsquarefeet12 = tf.feature_column.numeric_column(\"finishedsquarefeet12\")\n",
    "    fullbathcnt = tf.feature_column.numeric_column(\"fullbathcnt\")\n",
    "    latitude = tf.feature_column.numeric_column(\"latitude\")\n",
    "    longitude = tf.feature_column.numeric_column(\"longitude\")\n",
    "    # treat rawcensustractandblock as numerical data\n",
    "    rawcensustractandblock = tf.feature_column.numeric_column(\"rawcensustractandblock\")\n",
    "    # census causes nan in training\n",
    "    censustractandblock = tf.feature_column.numeric_column(\"censustractandblock\")\n",
    "    roomcnt = tf.feature_column.numeric_column(\"roomcnt\")\n",
    "    yearbuilt = tf.feature_column.numeric_column(\"yearbuilt\")\n",
    "    structuretaxvaluedollarcnt = tf.feature_column.numeric_column(\"structuretaxvaluedollarcnt\")\n",
    "    taxvaluedollarcnt = tf.feature_column.numeric_column(\"taxvaluedollarcnt\")\n",
    "    assessmentyear = tf.feature_column.numeric_column(\"assessmentyear\")\n",
    "    landtaxvaluedollarcnt = tf.feature_column.numeric_column(\"landtaxvaluedollarcnt\")\n",
    "    taxamount = tf.feature_column.numeric_column(\"taxamount\")\n",
    "\n",
    "    numeric_features = [\n",
    "        bathroomcnt, bedroomcnt, calculatedbathnbr, calculatedfinishedsquarefeet, finishedsquarefeet12,\n",
    "        fullbathcnt, latitude, longitude, rawcensustractandblock, roomcnt, yearbuilt, structuretaxvaluedollarcnt,\n",
    "        taxvaluedollarcnt, assessmentyear, landtaxvaluedollarcnt, taxamount\n",
    "    ]\n",
    "    \n",
    "    # categorical features \n",
    "    fips = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        \"fips\", [\n",
    "            \"06037\", \"06059\", \"06111\"\n",
    "        ])\n",
    "    propertycountylandusecode = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        \"propertycountylandusecode\", hash_bucket_size=100)\n",
    "    propertylandusetypeid = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        \"propertylandusetypeid\", hash_bucket_size=20)\n",
    "    regionidcity = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        \"regionidcity\", hash_bucket_size=300)\n",
    "    regionidcounty = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        \"regionidcounty\", [\n",
    "            \"1286\", \"2061\", \"3101\"\n",
    "        ])\n",
    "    regionidzip = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        \"regionidzip\", hash_bucket_size=500)\n",
    "\n",
    "    categorical_features = [\n",
    "        fips, propertycountylandusecode, propertylandusetypeid, regionidcity, regionidcounty, regionidzip\n",
    "    ]\n",
    "    \n",
    "    wide_columns = numeric_features + categorical_features\n",
    "    \n",
    "    deep_columns = [\n",
    "        tf.feature_column.indicator_column(fips),\n",
    "        tf.feature_column.embedding_column(propertycountylandusecode, dimension=7),\n",
    "        tf.feature_column.embedding_column(propertylandusetypeid, dimension=6),\n",
    "        tf.feature_column.embedding_column(regionidcity, dimension=8),\n",
    "        tf.feature_column.indicator_column(regionidcounty),\n",
    "        tf.feature_column.embedding_column(regionidzip, dimension=9),\n",
    "    ]\n",
    "    \n",
    "    deep_columns += numeric_features\n",
    "    return wide_columns, deep_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_estimator(model_dir, model_type):\n",
    "    wide_columns, deep_columns = build_model_columns()\n",
    "    hidden_units = [1000, 750, 500, 250]\n",
    "\n",
    "    if model_type == 'wide':\n",
    "        return tf.estimator.LinearRegressor(\n",
    "                model_dir=model_dir,\n",
    "                feature_columns=wide_columns)\n",
    "    elif model_type == 'deep':\n",
    "        return tf.estimator.DNNRegressor(\n",
    "                model_dir=model_dir,\n",
    "                feature_columns=deep_columns,\n",
    "                hidden_units=hidden_units)\n",
    "    else:\n",
    "        return tf.estimator.DNNLinearCombinedRegressor(\n",
    "                model_dir=model_dir,\n",
    "                linear_feature_columns=wide_columns,\n",
    "                dnn_feature_columns=deep_columns,\n",
    "                dnn_hidden_units=hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpsba459fz', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "model_dir = tempfile.mkdtemp()\n",
    "m = build_estimator(model_dir, 'combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpsba459fz/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.34194e+14, step = 1\n",
      "INFO:tensorflow:global_step/sec: 52.8358\n",
      "INFO:tensorflow:loss = 4.04384e+09, step = 101 (1.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.0846\n",
      "INFO:tensorflow:loss = 5.71326e+09, step = 201 (1.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.6231\n",
      "INFO:tensorflow:loss = 1.24063e+09, step = 301 (2.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.3059\n",
      "INFO:tensorflow:loss = 1.20395e+09, step = 401 (1.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.8917\n",
      "INFO:tensorflow:loss = 1.00864e+09, step = 501 (1.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.7153\n",
      "INFO:tensorflow:loss = 7.84098e+08, step = 601 (1.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.5765\n",
      "INFO:tensorflow:loss = 7.6294e+08, step = 701 (1.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.9483\n",
      "INFO:tensorflow:loss = 1.24793e+09, step = 801 (1.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.2025\n",
      "INFO:tensorflow:loss = 8.57005e+08, step = 901 (1.845 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpsba459fz/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7.61993e+08.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn_linear_combined.DNNLinearCombinedRegressor at 0x7f011ab9a390>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.train(input_fn=input_fn(df_trainx, trainy, num_epochs=None), steps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-11-26-21:57:28\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpsba459fz/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-26-21:57:31\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 9.15472e+06, global_step = 1000, loss = 9.13196e+08\n"
     ]
    }
   ],
   "source": [
    "results = m.evaluate(input_fn=input_fn(df_testx, testy, num_threads=1, num_epochs = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
